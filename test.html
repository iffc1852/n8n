<!DOCTYPE html>
<html lang="zh-TW">
<head>
<meta charset="UTF-8" />
<title>èªéŸ³äº’å‹• AI åŠ©ç†ï¼ˆç©©å®šç‰ˆï¼‰</title>
<style>
  body { font-family:sans-serif;text-align:center;margin-top:40px; }
  input,button{padding:8px;margin:5px;}
  #status{margin-top:20px;font-size:18px;}
  #meterContainer{width:300px;height:20px;background:#ddd;border-radius:10px;margin:20px auto;overflow:hidden;display:none;}
  #meterBar{height:100%;width:0%;background:linear-gradient(to right,#4CAF50,#FFEB3B,#F44336);transition:width 0.05s;}
</style>
</head>
<body>
<h2>ğŸ¤– èªéŸ³äº’å‹• AI åŠ©ç†ï¼ˆç©©å®šéŒ„éŸ³ç‰ˆï¼‰</h2>
<input id="aiName" placeholder="AI åç¨± (ä¾‹å¦‚ å°æ™º)" /><br>
<input id="webhookUrl" placeholder="n8n Webhook URL" /><br>
<button id="startBtn">å•Ÿå‹•èªéŸ³ç›£è½</button>
<div id="meterContainer"><div id="meterBar"></div></div>
<p id="status">å°šæœªå•Ÿå‹•</p>

<script>
let aiName="", n8nUrl="", rec, mediaRecorder;
let audioChunks=[], audioContext, analyser, source;
let isRecording=false, meterBar=document.getElementById("meterBar"), meterContainer=document.getElementById("meterContainer");

document.getElementById("startBtn").addEventListener("click",async()=>{
  aiName=document.getElementById("aiName").value.trim();
  n8nUrl=document.getElementById("webhookUrl").value.trim();
  if(!aiName||!n8nUrl){alert("è«‹è¼¸å…¥ AI åç¨±èˆ‡ Webhook URLï¼");return;}
  await navigator.mediaDevices.getUserMedia({audio:true}); // è¦æ±‚æ¬Šé™
  startWakeListener();
});

function startWakeListener(){
  if(rec) try{rec.abort();}catch{}
  rec=new(window.SpeechRecognition||window.webkitSpeechRecognition)();
  rec.lang="zh-TW"; rec.continuous=true; rec.interimResults=false;

  rec.onstart=()=>{document.getElementById("status").innerText="ğŸ§ å·²å•Ÿå‹•å–šé†’ï¼ˆèªªå‡º AI åç¨±ï¼‰";};
  rec.onresult=(e)=>{
    const txt=e.results[e.results.length-1][0].transcript.trim();
    console.log("è½åˆ°:",txt);
    if(txt.includes(aiName)){
      document.getElementById("status").innerText=`âœ… åµæ¸¬åˆ°ã€Œ${aiName}ã€ï¼Œæº–å‚™éŒ„éŸ³...`;
      rec.abort(); // âš ï¸ å®Œå…¨ä¸­æ–·è¾¨è­˜ï¼Œé‡‹æ”¾éŸ³æº
      setTimeout(startMainRecording,1000); // å»¶é² 1 ç§’å•Ÿå‹•éŒ„éŸ³
    }
  };
  rec.onerror=(err)=>console.warn("å–šé†’éŒ¯èª¤:",err);
  rec.onend=()=>{ if(!isRecording) setTimeout(()=>rec.start(),1000); };
  rec.start();
}

// ===== éŒ„éŸ³éšæ®µ =====
async function startMainRecording(){
  isRecording=true;
  meterContainer.style.display="block";
  document.getElementById("status").innerText="ğŸ™ï¸ æ­£åœ¨éŒ„éŸ³...";
  try{
    // âœ… é‡æ–°é–‹å•Ÿå…¨æ–°éŸ³æºï¼Œé¿å… SpeechRecognition çš„èˆŠæµ
    const stream=await navigator.mediaDevices.getUserMedia({
      audio:{ echoCancellation:true, noiseSuppression:true, channelCount:1 }
    });

    mediaRecorder=new MediaRecorder(stream,{mimeType:"audio/webm;codecs=opus"});
    audioChunks=[];
    audioContext=new AudioContext();
    source=audioContext.createMediaStreamSource(stream);
    analyser=audioContext.createAnalyser();
    analyser.fftSize=2048;
    source.connect(analyser);

    mediaRecorder.ondataavailable=e=>audioChunks.push(e.data);
    mediaRecorder.onstop=async()=>{
      isRecording=false; meterContainer.style.display="none";
      const blob=new Blob(audioChunks,{type:"audio/webm"});
      console.log("éŒ„éŸ³å¤§å°:",blob.size,"bytes");
      if(blob.size<1500){document.getElementById("status").innerText="âš ï¸ æ²’éŒ„åˆ°è²éŸ³ï¼Œå›åˆ°ç›£è½...";startWakeListener();return;}
      const formData=new FormData(); formData.append("file",blob,"voice.webm");
      document.getElementById("status").innerText="ğŸ“¤ ä¸Šå‚³ä¸­...";
      try{
        const res=await fetch(n8nUrl,{method:"POST",body:formData});
        const result=await res.json();
        if(result.success&&result.audio){
          const audio=new Audio("data:audio/mp3;base64,"+result.audio);
          audio.play();
          document.getElementById("status").innerText="ğŸ”Š æ’­æ”¾å›è¦†ä¸­...";
          audio.onended=()=>{document.getElementById("status").innerText="ğŸ§ å›åˆ°å–šé†’æ¨¡å¼";startWakeListener();};
        }else{document.getElementById("status").innerText="âš ï¸ å›å‚³éŒ¯èª¤";startWakeListener();}
      }catch(err){console.error(err);document.getElementById("status").innerText="âŒ ä¸Šå‚³å¤±æ•—";startWakeListener();}
    };

    mediaRecorder.start();
    detectSilenceAndVisualize();
  }catch(err){
    console.error("éŒ„éŸ³éŒ¯èª¤:",err);
    isRecording=false; meterContainer.style.display="none"; startWakeListener();
  }
}

// ===== éœéŸ³åµæ¸¬ + éŸ³é‡æ¢ =====
function detectSilenceAndVisualize(){
  const buffer=new Uint8Array(analyser.fftSize);
  let silenceDuration=0;
  function loop(){
    if(!isRecording)return;
    analyser.getByteTimeDomainData(buffer);
    const max=Math.max(...buffer.map(v=>Math.abs(v-128)));
    const volume=Math.min(100,max*1.2);
    meterBar.style.width=volume+"%";
    if(max<20)silenceDuration+=0.1; else silenceDuration=0;
    if(silenceDuration>=3&&mediaRecorder&&mediaRecorder.state==="recording"){
      document.getElementById("status").innerText="ğŸ›‘ åµæ¸¬åˆ° 3 ç§’ç„¡è²ï¼Œè‡ªå‹•çµæŸ";
      mediaRecorder.stop(); return;
    }
    requestAnimationFrame(loop);
  }
  requestAnimationFrame(loop);
}
</script>
</body>
</html>
