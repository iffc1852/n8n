<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8" />
  <title>🎙️ ChatGPT Voice 風格語音助理</title>
  <style>
    body { font-family: "Microsoft JhengHei", sans-serif; text-align: center; margin-top: 40px; }
    input, button { padding: 8px; margin: 5px; width: 260px; font-size: 16px; }
    #status { margin-top: 20px; font-size: 18px; color: #333; }
  </style>
</head>
<body>
  <h2>🤖 ChatGPT Voice 模式語音助理</h2>
  <input id="aiName" placeholder="輸入喚醒詞 (例如 小文)" /><br>
  <input id="webhookUrl" placeholder="n8n Webhook URL" /><br>
  <button onclick="startWakeListener()">🚀 啟動語音監聽</button>
  <p id="status">尚未啟動</p>

  <script>
    // ===== 全域變數 =====
    let aiName = "";
    let n8nUrl = "";
    let rec;                // SpeechRecognition 實例
    let isRecognitionActive = false;
    let mediaRecorder;
    let audioChunks = [];
    let silenceTimer = null;

    // -----------------------------------------------------
    // [1] 啟動喚醒監聽：使用 SpeechRecognition
    // -----------------------------------------------------
    function startWakeListener() {
      aiName = document.getElementById("aiName").value.trim();
      n8nUrl = document.getElementById("webhookUrl").value.trim();
      if (!aiName || !n8nUrl) {
        alert("請輸入喚醒詞與 n8n Webhook URL！");
        return;
      }

      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      rec = new SpeechRecognition();
      rec.lang = "zh-TW";
      rec.continuous = true;       // 持續監聽
      rec.interimResults = false;

      // ===== 當有辨識結果時 =====
      rec.onresult = async (e) => {
        const txt = e.results[e.results.length - 1][0].transcript.trim();
        console.log("🎧 聽到:", txt);
        document.getElementById("status").innerText = "🎧 聽到: " + txt;

        // ✅ 若包含喚醒詞（AI 名稱），則啟動錄音
        if (txt.includes(aiName)) {
          console.log("✅ 偵測到喚醒詞:", aiName);
          document.getElementById("status").innerText = `✅ 喚醒「${aiName}」成功，準備錄音...`;
          try { rec.abort(); } catch (err) {}
          isRecognitionActive = false;

          // 🔽 等待麥克風釋放（關鍵）
          await waitMicReady();

          // 🔽 開始主錄音流程
          await startMainRecording();
        }
      };

      // ===== 若發生錯誤 =====
      rec.onerror = (err) => {
        if (err.error === "aborted") {
          console.log("🎤 辨識中止（準備錄音）");
        } else {
          console.warn("⚠️ 喚醒錯誤:", err.error);
        }
        isRecognitionActive = false;
      };

      // ===== 辨識結束後自動重啟 =====
      rec.onend = () => {
        if (!isRecognitionActive) {
          console.log("🔁 喚醒監聽重新啟動中...");
          setTimeout(() => rec.start(), 800);
          isRecognitionActive = true;
        }
      };

      rec.start();
      isRecognitionActive = true;
      document.getElementById("status").innerText = "🎤 已啟動喚醒監聽中...";
    }

    // -----------------------------------------------------
    // [2] 等待麥克風釋放（Chrome 需要）
    // -----------------------------------------------------
    async function waitMicReady(maxWait = 2000) {
      console.log("⏳ 等待麥克風釋放中...");
      const start = Date.now();

      while (Date.now() - start < maxWait) {
        try {
          const test = await navigator.mediaDevices.getUserMedia({ audio: true });
          const track = test.getAudioTracks()[0];
          if (track.readyState === "live") {
            track.stop();
            console.log("🎤 麥克風釋放完成");
            return;
          }
        } catch {}
        await new Promise(r => setTimeout(r, 150));
      }
      console.warn("⚠️ 麥克風仍未釋放，強制繼續");
    }

    // -----------------------------------------------------
    // [3] 主錄音流程
    // -----------------------------------------------------
    async function startMainRecording() {
      console.log("🎙️ 開始錄音階段...");
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioChunks = [];
      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);

      mediaRecorder.onstop = async () => {
        const blob = new Blob(audioChunks, { type: "audio/webm" });
        console.log("📦 錄音完成，大小:", blob.size, "bytes");

        const formData = new FormData();
        formData.append("audio_file", blob, "voice.webm"); // 確保與 n8n 對應

        document.getElementById("status").innerText = "📤 傳送錄音中...";

        try {
          const res = await fetch(n8nUrl, { method: "POST", body: formData });
          const text = await res.text();
          console.log("📥 Raw Response:", text);

          if (!text) throw new Error("伺服器無回應");
          const result = JSON.parse(text);

          if (result.success && result.audio) {
            const audio = new Audio("data:audio/mp3;base64," + result.audio);
            audio.play();
            document.getElementById("status").innerText = "🔊 播放 AI 回覆中...";
          } else {
            document.getElementById("status").innerText = "⚠️ 回傳資料格式錯誤";
          }
        } catch (err) {
          console.error("上傳錯誤:", err);
          document.getElementById("status").innerText = "❌ 上傳失敗，請檢查 n8n 回應";
        }

        // 🔁 錄音完畢 → 回到喚醒模式
        startWakeListener();
      };

      // 開始錄音
      mediaRecorder.start();
      document.getElementById("status").innerText = "🎙️ 錄音中...(3 秒無聲會自動結束)";
      detectSilence(stream);
    }

    // -----------------------------------------------------
    // [4] 靜音自動結束錄音
    // -----------------------------------------------------
    function detectSilence(stream) {
      const audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      source.connect(analyser);
      const buffer = new Uint8Array(analyser.fftSize);
      let silenceDuration = 0;

      function loop() {
        analyser.getByteTimeDomainData(buffer);
        let max = Math.max(...buffer.map(v => Math.abs(v - 128)));
        if (max < 10) silenceDuration += 0.1;
        else silenceDuration = 0;

        if (silenceDuration >= 3 && mediaRecorder && mediaRecorder.state === "recording") {
          console.log("🛑 偵測到 3 秒無聲，自動結束錄音");
          mediaRecorder.stop();
          stream.getTracks().forEach(t => t.stop());
          return;
        }
        requestAnimationFrame(loop);
      }
      requestAnimationFrame(loop);
    }
  </script>
</body>
</html>
