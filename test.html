<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
  <title>èªéŸ³äº’å‹• AI åŠ©ç†</title>
  <style>
    body { font-family: sans-serif; text-align: center; margin-top: 40px; }
    input { padding: 8px; margin: 5px; width: 250px; }
    #status { margin-top: 20px; font-size: 18px; color: #444; }
  </style>
</head>
<body>
  <h2>ğŸ¤– èªéŸ³äº’å‹• AI åŠ©ç†</h2>
  <p>è¼¸å…¥ä½ çš„ AI åç¨±èˆ‡ n8n Webhook ç¶²å€ï¼š</p>
  <input id="aiName" placeholder="AI åç¨± (ä¾‹å¦‚ å°æ™º)" /><br>
  <input id="webhookUrl" placeholder="n8n Webhook URL" /><br>
  <button onclick="startWakeListener()">å•Ÿå‹•èªéŸ³ç›£è½</button>
  <p id="status">å°šæœªå•Ÿå‹•</p>

  <script>
    let aiName = "";
    let n8nUrl = "";
    let mediaRecorder;
    let audioChunks = [];
    let audioContext, analyser, source;

    let rec; // å…¨åŸŸä¿å­˜ SpeechRecognition å¯¦ä¾‹

    // ===== [1] å•Ÿå‹•èªéŸ³å–šé†’ç›£è½ =====
    function startWakeListener() {
      aiName = document.getElementById("aiName").value.trim();
      n8nUrl = document.getElementById("webhookUrl").value.trim();

      if (!aiName || !n8nUrl) {
        alert("è«‹è¼¸å…¥ AI åç¨±èˆ‡ Webhook URLï¼");
        return;
      }

      // è‹¥å·²æœ‰è¾¨è­˜å™¨ï¼Œå…ˆä¸­æ­¢é¿å…é‡è¤‡
      if (rec) rec.abort();

      rec = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      rec.lang = 'zh-TW';
      rec.continuous = true;
      rec.interimResults = false;

      rec.onresult = (event) => {
        const transcript = event.results[event.results.length - 1][0].transcript.trim();
        console.log("ğŸ§ åµæ¸¬åˆ°èªéŸ³:", transcript);
        document.getElementById("status").innerText = "è½åˆ°: " + transcript;

        // è‹¥åµæ¸¬åˆ° AI åç¨± â†’ åœæ­¢ç›£è½ä¸¦é–‹å§‹éŒ„éŸ³
        if (transcript.includes(aiName)) {
          document.getElementById("status").innerText = `âœ… å–šé†’ã€Œ${aiName}ã€æˆåŠŸï¼Œé–‹å§‹éŒ„éŸ³ï¼`;
          rec.stop(); // æš«åœå–šé†’ç›£è½
          startMainRecording(); // é€²å…¥éŒ„éŸ³éšæ®µ
        }
      };

      rec.onerror = (err) => console.error("å–šé†’éŒ¯èª¤:", err);
      rec.onend = () => {
        console.log("å–šé†’ç›£è½çµæŸï¼Œé‡æ–°å•Ÿå‹•...");
        setTimeout(() => rec.start(), 1000);
      };

      rec.start();
      document.getElementById("status").innerText = "ğŸ¤ å·²å•Ÿå‹•å–šé†’ç›£è½...";
    }

    // ===== [2] éŒ„éŸ³éšæ®µ =====
    async function startMainRecording() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioChunks = [];

      // âœ… æŒ‡å®š Opus ç·¨ç¢¼ï¼Œç¢ºä¿ Whisper èƒ½è§£æ
      mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm;codecs=opus" });

      audioContext = new AudioContext();
      source = audioContext.createMediaStreamSource(stream);
      analyser = audioContext.createAnalyser();
      source.connect(analyser);

      mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
      mediaRecorder.onstop = async () => {
        const blob = new Blob(audioChunks, { type: "audio/webm" });
        const formData = new FormData();
        formData.append("audio_file", blob, "voice.webm"); // â† n8n å°æ‡‰çš„ binary åç¨±

        document.getElementById("status").innerText = "ğŸ“¤ å‚³é€éŒ„éŸ³ä¸­...";

        try {
          const res = await fetch(n8nUrl, { method: "POST", body: formData });
          const result = await res.json();
          console.log("ä¼ºæœå™¨å›å‚³:", result);

          if (result.success && result.audio) {
            const audio = new Audio("data:audio/mp3;base64," + result.audio);
            audio.play();
            document.getElementById("status").innerText = "ğŸ”Š æ’­æ”¾ AI å›è¦†ä¸­...";
            audio.onended = () => {
              // æ’­æ”¾çµæŸå¾Œå†é‡æ–°å›åˆ°å–šé†’ç›£è½
              document.getElementById("status").innerText = "ğŸ¤ ç­‰å¾…ä¸‹ä¸€æ¬¡å–šé†’...";
              startWakeListener();
            };
          } else {
            document.getElementById("status").innerText = "âš ï¸ å›å‚³è³‡æ–™éŒ¯èª¤";
            startWakeListener(); // å³ä½¿éŒ¯èª¤ä¹Ÿå›å¾©ç›£è½
          }
        } catch (err) {
          console.error("å‚³é€éŒ¯èª¤:", err);
          document.getElementById("status").innerText = "âŒ ä¸Šå‚³å¤±æ•—";
          startWakeListener(); // å¤±æ•—ä¹Ÿå›å¾©ç›£è½
        }
      };

      mediaRecorder.start();
      document.getElementById("status").innerText = "ğŸ™ï¸ éŒ„éŸ³ä¸­...(3 ç§’ç„¡è²è‡ªå‹•çµæŸ)";
      detectSilence();
    }

    // ===== [3] åµæ¸¬éœéŸ³çµæŸ =====
    function detectSilence() {
      const buffer = new Uint8Array(analyser.fftSize);
      let silenceDuration = 0;

      function loop() {
        analyser.getByteTimeDomainData(buffer);
        let max = Math.max(...buffer.map(v => Math.abs(v - 128)));

        if (max < 20) { // éœéŸ³é–¾å€¼
          silenceDuration += 0.1;
        } else {
          silenceDuration = 0;
        }

        if (silenceDuration >= 3 && mediaRecorder && mediaRecorder.state === "recording") {
          document.getElementById("status").innerText = "ğŸ›‘ åµæ¸¬åˆ° 3 ç§’ç„¡è²ï¼Œè‡ªå‹•çµæŸéŒ„éŸ³";
          mediaRecorder.stop();
          return;
        }

        requestAnimationFrame(loop);
      }
      requestAnimationFrame(loop);
    }
  </script>
</body>
</html>
