<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8" />
  <title>🎙️ ChatGPT Voice 最終穩定版語音助理</title>
  <style>
    body { font-family: "Microsoft JhengHei", sans-serif; text-align: center; margin-top: 40px; }
    input, button { padding: 8px; margin: 5px; width: 260px; font-size: 16px; }
    #status { margin-top: 20px; font-size: 18px; color: #333; }
  </style>
</head>
<body>
  <h2>🤖 ChatGPT Voice 最終穩定版語音助理</h2>
  <input id="aiName" placeholder="輸入喚醒詞 (例如 小文1)" /><br>
  <input id="webhookUrl" placeholder="n8n Webhook URL" /><br>
  <button onclick="startWakeListener()">🚀 啟動語音監聽</button>
  <p id="status">尚未啟動</p>

  <script>
    // ===== 全域變數 =====
    let aiName = "";
    let n8nUrl = "";
    let rec;                           // SpeechRecognition 實例
    let isRecognitionActive = false;   // 是否正在語音辨識
    let shouldRecordAfterEnd = false;  // 旗標：在辨識完全結束後是否要錄音
    let mediaRecorder;
    let audioChunks = [];

    // -----------------------------------------------------
    // [1] 啟動喚醒監聽：SpeechRecognition
    // -----------------------------------------------------
    function startWakeListener() {
      aiName = document.getElementById("aiName").value.trim();
      n8nUrl = document.getElementById("webhookUrl").value.trim();
      if (!aiName || !n8nUrl) {
        alert("請輸入喚醒詞與 n8n Webhook URL！");
        return;
      }

      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      rec = new SpeechRecognition();
      rec.lang = "zh-TW";
      rec.continuous = true;       // 持續監聽
      rec.interimResults = false;  // 不輸出中間結果

      // === 語音辨識結果事件 ===
      rec.onresult = (e) => {
        const txt = e.results[e.results.length - 1][0].transcript.trim();
        console.log("🎧 聽到:", txt);
        document.getElementById("status").innerText = "🎧 聽到: " + txt;

        // ✅ 若包含喚醒詞（AI 名稱）
        if (txt.includes(aiName)) {
          console.log("✅ 偵測到喚醒詞:", aiName);
          document.getElementById("status").innerText = `✅ 喚醒「${aiName}」成功，準備錄音...`;
          shouldRecordAfterEnd = true;  // 在 onend 事件中啟動錄音
          rec.abort(); // 中止辨識（等完全結束後再錄音）
        }
      };

      // === 錯誤事件 ===
      rec.onerror = (err) => {
        if (err.error === "aborted") {
          console.log("🎤 辨識中止（準備錄音）");
        } else {
          console.warn("⚠️ 喚醒錯誤:", err.error);
        }
        isRecognitionActive = false;
      };

      // === 辨識完全結束事件 ===
      rec.onend = async () => {
        // ✅ 若剛剛因喚醒詞中止 → 現在正式開始錄音
        if (shouldRecordAfterEnd) {
          shouldRecordAfterEnd = false;
          console.log("🎤 SpeechRecognition 已完全結束，準備開始錄音...");
          await waitMicReady();
          await startMainRecording();
          return;
        }

        // 🧩 若目前沒在錄音 → 自動重啟辨識（維持喚醒狀態）
        if (!mediaRecorder || mediaRecorder.state !== "recording") {
          console.log("🔁 喚醒監聽重新啟動中...");
          setTimeout(() => rec.start(), 800);
          isRecognitionActive = true;
        } else {
          console.log("🛑 錄音期間禁止自動重啟辨識");
        }
      };

      // 啟動喚醒監聽
      rec.start();
      isRecognitionActive = true;
      document.getElementById("status").innerText = "🎤 已啟動喚醒監聽中...";
    }

    // -----------------------------------------------------
    // [2] 等待麥克風釋放（確保不被 SpeechRecognition 佔用）
    // -----------------------------------------------------
    async function waitMicReady(maxWait = 2000) {
      console.log("⏳ 等待麥克風釋放中...");
      const start = Date.now();
      while (Date.now() - start < maxWait) {
        try {
          const test = await navigator.mediaDevices.getUserMedia({ audio: true });
          const track = test.getAudioTracks()[0];
          if (track.readyState === "live") {
            track.stop();
            console.log("🎤 麥克風釋放完成");
            return;
          }
        } catch {}
        await new Promise(r => setTimeout(r, 150));
      }
      console.warn("⚠️ 麥克風仍未釋放，強制繼續");
    }

    // -----------------------------------------------------
    // [3] 錄音主流程
    // -----------------------------------------------------
    async function startMainRecording() {
      console.log("🎙️ 開始錄音階段...");
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioChunks = [];
      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);

      // 🔹 錄音結束時上傳音訊給 n8n
      mediaRecorder.onstop = async () => {
        const blob = new Blob(audioChunks, { type: "audio/webm" });
        console.log("📦 錄音完成，大小:", blob.size, "bytes");
        const formData = new FormData();
        formData.append("audio_file", blob, "voice.webm");

        document.getElementById("status").innerText = "📤 傳送錄音中...";
        try {
          console.log("📤 已上傳錄音，等待伺服器回覆...");
          const res = await fetch(n8nUrl, { method: "POST", body: formData });

            // 🔹 伺服器回傳二進位音檔（mp3）
          if (!res.ok) throw new Error("伺服器回應錯誤：" + res.status);
          const blob = await res.blob();
          console.log("📥 收到音訊 Blob:", blob);

          const audioUrl = URL.createObjectURL(blob);
          const audio = new Audio(audioUrl);
          audio.autoplay = true;
          audio.volume = 1.0;

          audio.play().then(() => {
            console.log("🔊 播放成功！");
            document.getElementById("status").innerText = "🔊 播放 AI 回覆中...";
            }).catch(err => {
            console.warn("⚠️ 自動播放被瀏覽器阻擋:", err);
            const btn = document.createElement("button");
            btn.innerText = "▶️ 播放 AI 回覆";
            btn.onclick = () => audio.play();
            const status = document.getElementById("status");
            status.innerHTML = "";
            status.appendChild(btn);
});

// ✅ 播放完畢後自動恢復喚醒監聽
audio.onended = () => {
  console.log("🎤 AI 回覆播放結束，自動回到喚醒模式");
  startWakeListener();
};

        // 錄音結束後 → 自動回到喚醒模式
        startWakeListener();
      };

      // 🔹 啟動錄音
      mediaRecorder.start();
      document.getElementById("status").innerText = "🎙️ 錄音中...(靜音 3 秒會自動結束)";

      // 🕐 延遲 1 秒後再啟動靜音偵測，避免誤判開頭空白
      setTimeout(() => {
        console.log("🔊 啟動靜音偵測（延遲 1 秒）");
        detectSilence(stream);
      }, 1000);
    }

    // -----------------------------------------------------
    // [4] 靜音偵測：必須先有聲音才開始倒數
    // -----------------------------------------------------
    function detectSilence(stream) {
      const audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      source.connect(analyser);
      const buffer = new Uint8Array(analyser.fftSize);

      let silenceDuration = 0;  // 已靜音秒數
      let hasVoice = false;     // 是否已出現人聲
      let lastActive = 0;       // 最近有聲音時間戳

      function loop() {
        analyser.getByteTimeDomainData(buffer);
        let max = Math.max(...buffer.map(v => Math.abs(v - 128)));
        const now = audioContext.currentTime;

        // 🎙️ 若音量超過閾值（偵測到人聲）
        if (max > 15) { // 可調整閾值 10～20 視麥克風靈敏度
          if (!hasVoice) console.log("🗣️ 偵測到人聲，開始啟動靜音計時監控");
          hasVoice = true;
          lastActive = now;
          silenceDuration = 0;
        } else if (hasVoice) {
          // ✅ 只有在出現過人聲後，才開始累計靜音時間
          silenceDuration = now - lastActive;
        }

        // 🧠 若已出現過人聲、且靜音超過 3 秒 → 自動停止錄音
        if (hasVoice && silenceDuration >= 3 && mediaRecorder && mediaRecorder.state === "recording") {
          console.log("🛑 偵測到 3 秒無聲，自動結束錄音");
          mediaRecorder.stop();
          stream.getTracks().forEach(t => t.stop());
          return;
        }

        requestAnimationFrame(loop);
      }

      requestAnimationFrame(loop);
    }
  </script>
</body>
</html>



