<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
  <title>èªéŸ³äº’å‹• AI åŠ©ç†</title>
  <style>
    body { font-family: sans-serif; text-align: center; margin-top: 40px; }
    input { padding: 8px; margin: 5px; width: 250px; }
    button { padding: 10px 20px; margin-top: 10px; cursor: pointer; }
    #status { margin-top: 20px; font-size: 18px; color: #333; }
  </style>
</head>
<body>
  <h2>ğŸ¤– èªéŸ³äº’å‹• AI åŠ©ç†</h2>
  <p>è¼¸å…¥ä½ çš„ AI åç¨±èˆ‡ n8n Webhook ç¶²å€ï¼š</p>
  <input id="aiName" placeholder="AI åç¨± (ä¾‹å¦‚ å°æ™º)" /><br>
  <input id="webhookUrl" placeholder="n8n Webhook URL" /><br>
  <button id="startBtn">å•Ÿå‹•èªéŸ³ç›£è½</button>
  <p id="status">å°šæœªå•Ÿå‹•</p>

  <script>
    let aiName = "";
    let n8nUrl = "";
    let rec;
    let mediaRecorder;
    let audioChunks = [];
    let audioContext, analyser, source;
    let silenceTimer = null;
    let isRecording = false;

    document.getElementById("startBtn").addEventListener("click", async () => {
      aiName = document.getElementById("aiName").value.trim();
      n8nUrl = document.getElementById("webhookUrl").value.trim();
      if (!aiName || !n8nUrl) {
        alert("è«‹è¼¸å…¥ AI åç¨±èˆ‡ Webhook URLï¼");
        return;
      }

      document.getElementById("status").innerText = "ğŸ¤ æ­£åœ¨åˆå§‹åŒ–éº¥å…‹é¢¨...";
      try {
        // âœ… å…ˆè«‹æ±‚éº¥å…‹é¢¨æ¬Šé™
        await navigator.mediaDevices.getUserMedia({ audio: true });
        startWakeListener(); // å•Ÿå‹•å–šé†’
      } catch (err) {
        alert("è«‹å…è¨±éº¥å…‹é¢¨æ¬Šé™ï¼š" + err.message);
      }
    });

    // ===== [1] èªéŸ³å–šé†’ =====
    function startWakeListener() {
      try {
        if (rec) rec.abort();
        rec = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        rec.lang = "zh-TW";
        rec.continuous = true;
        rec.interimResults = false;

        rec.onstart = () => {
          document.getElementById("status").innerText = "ğŸ§ å·²å•Ÿå‹•èªéŸ³å–šé†’ï¼ˆèªªå‡º AI åç¨±ä»¥é–‹å§‹éŒ„éŸ³ï¼‰";
        };

        rec.onresult = (event) => {
          const transcript = event.results[event.results.length - 1][0].transcript.trim();
          console.log("è½åˆ°:", transcript);
          if (transcript.includes(aiName)) {
            document.getElementById("status").innerText = `âœ… åµæ¸¬åˆ°å–šé†’è©ã€Œ${aiName}ã€ï¼Œé–‹å§‹éŒ„éŸ³ï¼`;
            rec.stop();
            startMainRecording();
          }
        };

        rec.onerror = (err) => {
          console.warn("SpeechRecognition éŒ¯èª¤:", err);
          if (!isRecording) setTimeout(() => rec.start(), 1500);
        };

        rec.onend = () => {
          if (!isRecording) {
            console.log("èªéŸ³ç›£è½çµæŸï¼Œè‡ªå‹•é‡å•Ÿ...");
            setTimeout(() => rec.start(), 1000);
          }
        };

        rec.start();
      } catch (err) {
        alert("SpeechRecognition åˆå§‹åŒ–å¤±æ•—ï¼š" + err.message);
      }
    }

    // ===== [2] éŒ„éŸ³éšæ®µ =====
    async function startMainRecording() {
      isRecording = true;
      try {
        // é—œé–‰ SpeechRecognition
        if (rec && rec.stop) try { rec.stop(); } catch {}

        await new Promise(r => setTimeout(r, 500)); // ç­‰éº¥å…‹é¢¨é‡‹æ”¾

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm;codecs=opus" });
        audioChunks = [];

        audioContext = new AudioContext();
        source = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        source.connect(analyser);

        mediaRecorder.ondataavailable = e => audioChunks.push(e.data);

        mediaRecorder.onstop = async () => {
          isRecording = false;
          const blob = new Blob(audioChunks, { type: "audio/webm" });
          console.log("éŒ„éŸ³æª”æ¡ˆå¤§å°:", blob.size, "bytes");

          if (blob.size < 2000) {
            document.getElementById("status").innerText = "âš ï¸ æ²’æœ‰éŒ„åˆ°æœ‰æ•ˆè²éŸ³ï¼Œå›åˆ°ç›£è½...";
            startWakeListener();
            return;
          }

          const formData = new FormData();
          formData.append("file", blob, "voice.webm");

          document.getElementById("status").innerText = "ğŸ“¤ ä¸Šå‚³éŒ„éŸ³ä¸­...";
          try {
            const res = await fetch(n8nUrl, { method: "POST", body: formData });
            const result = await res.json();
            console.log("ä¼ºæœå™¨å›å‚³:", result);

            if (result.success && result.audio) {
              const audio = new Audio("data:audio/mp3;base64," + result.audio);
              audio.play().catch(err => console.warn("æ’­æ”¾è¢«å°é–:", err));
              document.getElementById("status").innerText = "ğŸ”Š æ’­æ”¾ AI å›è¦†ä¸­...";
              audio.onended = () => {
                document.getElementById("status").innerText = "ğŸ¤ ç­‰å¾…ä¸‹ä¸€æ¬¡å–šé†’...";
                startWakeListener();
              };
            } else {
              document.getElementById("status").innerText = "âš ï¸ å›å‚³è³‡æ–™éŒ¯èª¤ï¼Œå›åˆ°ç›£è½æ¨¡å¼";
              startWakeListener();
            }
          } catch (err) {
            console.error("ä¸Šå‚³å¤±æ•—:", err);
            document.getElementById("status").innerText = "âŒ ä¸Šå‚³å¤±æ•—ï¼Œé‡æ–°ç›£è½";
            startWakeListener();
          }
        };

        mediaRecorder.start();
        document.getElementById("status").innerText = "ğŸ™ï¸ éŒ„éŸ³ä¸­...ï¼ˆ3 ç§’ç„¡è²è‡ªå‹•çµæŸï¼‰";
        detectSilence();

      } catch (err) {
        alert("éŒ„éŸ³åˆå§‹åŒ–éŒ¯èª¤ï¼š" + err.message);
        isRecording = false;
        startWakeListener();
      }
    }

    // ===== [3] åµæ¸¬éœéŸ³ï¼ˆ3 ç§’ç„¡è²çµæŸéŒ„éŸ³ï¼‰ =====
    function detectSilence() {
      const buffer = new Uint8Array(analyser.fftSize);
      let silenceDuration = 0;

      function loop() {
        if (!isRecording) return;
        analyser.getByteTimeDomainData(buffer);
        const max = Math.max(...buffer.map(v => Math.abs(v - 128)));

        if (max < 20) silenceDuration += 0.1;
        else silenceDuration = 0;

        if (silenceDuration >= 3 && mediaRecorder && mediaRecorder.state === "recording") {
          document.getElementById("status").innerText = "ğŸ›‘ åµæ¸¬åˆ° 3 ç§’ç„¡è²ï¼Œè‡ªå‹•çµæŸéŒ„éŸ³";
          mediaRecorder.stop();
          return;
        }
        requestAnimationFrame(loop);
      }
      requestAnimationFrame(loop);
    }
  </script>
</body>
</html>
