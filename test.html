<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8" />
  <title>ğŸ™ï¸ ChatGPT Voice æœ€çµ‚ç©©å®šç‰ˆèªéŸ³åŠ©ç†</title>
  <style>
    body { font-family: "Microsoft JhengHei", sans-serif; text-align: center; margin-top: 40px; }
    input, button { padding: 8px; margin: 5px; width: 260px; font-size: 16px; }
    #status { margin-top: 20px; font-size: 18px; color: #333; }
  </style>
</head>
<body>
  <h2>ğŸ¤– ChatGPT Voice æœ€çµ‚ç©©å®šç‰ˆèªéŸ³åŠ©ç†</h2>
  <input id="aiName" placeholder="è¼¸å…¥å–šé†’è© (ä¾‹å¦‚ å°æ–‡1)" /><br>
  <input id="webhookUrl" placeholder="n8n Webhook URL" /><br>
  <button onclick="startWakeListener()">ğŸš€ å•Ÿå‹•èªéŸ³ç›£è½</button>
  <p id="status">å°šæœªå•Ÿå‹•</p>

  <script>
    // ===== å…¨åŸŸè®Šæ•¸ =====
    let aiName = "";
    let n8nUrl = "";
    let rec;                           // SpeechRecognition å¯¦ä¾‹
    let isRecognitionActive = false;   // æ˜¯å¦æ­£åœ¨èªéŸ³è¾¨è­˜
    let shouldRecordAfterEnd = false;  // æ——æ¨™ï¼šåœ¨è¾¨è­˜å®Œå…¨çµæŸå¾Œæ˜¯å¦è¦éŒ„éŸ³
    let mediaRecorder;
    let audioChunks = [];

    // -----------------------------------------------------
    // [1] å•Ÿå‹•å–šé†’ç›£è½ï¼šSpeechRecognition
    // -----------------------------------------------------
    function startWakeListener() {
      aiName = document.getElementById("aiName").value.trim();
      n8nUrl = document.getElementById("webhookUrl").value.trim();
      if (!aiName || !n8nUrl) {
        alert("è«‹è¼¸å…¥å–šé†’è©èˆ‡ n8n Webhook URLï¼");
        return;
      }

      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      rec = new SpeechRecognition();
      rec.lang = "zh-TW";
      rec.continuous = true;       // æŒçºŒç›£è½
      rec.interimResults = false;  // ä¸è¼¸å‡ºä¸­é–“çµæœ

      // === èªéŸ³è¾¨è­˜çµæœäº‹ä»¶ ===
      rec.onresult = (e) => {
        const txt = e.results[e.results.length - 1][0].transcript.trim();
        console.log("ğŸ§ è½åˆ°:", txt);
        document.getElementById("status").innerText = "ğŸ§ è½åˆ°: " + txt;

        // âœ… è‹¥åŒ…å«å–šé†’è©ï¼ˆAI åç¨±ï¼‰
        if (txt.includes(aiName)) {
          console.log("âœ… åµæ¸¬åˆ°å–šé†’è©:", aiName);
          document.getElementById("status").innerText = `âœ… å–šé†’ã€Œ${aiName}ã€æˆåŠŸï¼Œæº–å‚™éŒ„éŸ³...`;
          shouldRecordAfterEnd = true;  // åœ¨ onend äº‹ä»¶ä¸­å•Ÿå‹•éŒ„éŸ³
          rec.abort(); // ä¸­æ­¢è¾¨è­˜ï¼ˆç­‰å®Œå…¨çµæŸå¾Œå†éŒ„éŸ³ï¼‰
        }
      };

      // === éŒ¯èª¤äº‹ä»¶ ===
      rec.onerror = (err) => {
        if (err.error === "aborted") {
          console.log("ğŸ¤ è¾¨è­˜ä¸­æ­¢ï¼ˆæº–å‚™éŒ„éŸ³ï¼‰");
        } else {
          console.warn("âš ï¸ å–šé†’éŒ¯èª¤:", err.error);
        }
        isRecognitionActive = false;
      };

      // === è¾¨è­˜å®Œå…¨çµæŸäº‹ä»¶ ===
      rec.onend = async () => {
        // âœ… è‹¥å‰›å‰›å› å–šé†’è©ä¸­æ­¢ â†’ ç¾åœ¨æ­£å¼é–‹å§‹éŒ„éŸ³
        if (shouldRecordAfterEnd) {
          shouldRecordAfterEnd = false;
          console.log("ğŸ¤ SpeechRecognition å·²å®Œå…¨çµæŸï¼Œæº–å‚™é–‹å§‹éŒ„éŸ³...");
          await waitMicReady();
          await startMainRecording();
          return;
        }

        // ğŸ§© è‹¥ç›®å‰æ²’åœ¨éŒ„éŸ³ â†’ è‡ªå‹•é‡å•Ÿè¾¨è­˜ï¼ˆç¶­æŒå–šé†’ç‹€æ…‹ï¼‰
        if (!mediaRecorder || mediaRecorder.state !== "recording") {
          console.log("ğŸ” å–šé†’ç›£è½é‡æ–°å•Ÿå‹•ä¸­...");
          setTimeout(() => rec.start(), 800);
          isRecognitionActive = true;
        } else {
          console.log("ğŸ›‘ éŒ„éŸ³æœŸé–“ç¦æ­¢è‡ªå‹•é‡å•Ÿè¾¨è­˜");
        }
      };

      // å•Ÿå‹•å–šé†’ç›£è½
      rec.start();
      isRecognitionActive = true;
      document.getElementById("status").innerText = "ğŸ¤ å·²å•Ÿå‹•å–šé†’ç›£è½ä¸­...";
    }

    // -----------------------------------------------------
    // [2] ç­‰å¾…éº¥å…‹é¢¨é‡‹æ”¾ï¼ˆç¢ºä¿ä¸è¢« SpeechRecognition ä½”ç”¨ï¼‰
    // -----------------------------------------------------
    async function waitMicReady(maxWait = 2000) {
      console.log("â³ ç­‰å¾…éº¥å…‹é¢¨é‡‹æ”¾ä¸­...");
      const start = Date.now();
      while (Date.now() - start < maxWait) {
        try {
          const test = await navigator.mediaDevices.getUserMedia({ audio: true });
          const track = test.getAudioTracks()[0];
          if (track.readyState === "live") {
            track.stop();
            console.log("ğŸ¤ éº¥å…‹é¢¨é‡‹æ”¾å®Œæˆ");
            return;
          }
        } catch {}
        await new Promise(r => setTimeout(r, 150));
      }
      console.warn("âš ï¸ éº¥å…‹é¢¨ä»æœªé‡‹æ”¾ï¼Œå¼·åˆ¶ç¹¼çºŒ");
    }

    // -----------------------------------------------------
    // [3] éŒ„éŸ³ä¸»æµç¨‹
    // -----------------------------------------------------
    async function startMainRecording() {
      console.log("ğŸ™ï¸ é–‹å§‹éŒ„éŸ³éšæ®µ...");
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioChunks = [];
      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);

      // ğŸ”¹ éŒ„éŸ³çµæŸæ™‚ä¸Šå‚³éŸ³è¨Šçµ¦ n8n
      mediaRecorder.onstop = async () => {
        const blob = new Blob(audioChunks, { type: "audio/webm" });
        console.log("ğŸ“¦ éŒ„éŸ³å®Œæˆï¼Œå¤§å°:", blob.size, "bytes");
        const formData = new FormData();
        formData.append("audio_file", blob, "voice.webm");

        document.getElementById("status").innerText = "ğŸ“¤ å‚³é€éŒ„éŸ³ä¸­...";
        try {
          console.log("ğŸ“¤ å·²ä¸Šå‚³éŒ„éŸ³ï¼Œç­‰å¾…ä¼ºæœå™¨å›è¦†...");
          const res = await fetch(n8nUrl, { method: "POST", body: formData });

            // ğŸ”¹ ä¼ºæœå™¨å›å‚³äºŒé€²ä½éŸ³æª”ï¼ˆmp3ï¼‰
          if (!res.ok) throw new Error("ä¼ºæœå™¨å›æ‡‰éŒ¯èª¤ï¼š" + res.status);
          const blob = await res.blob();
          console.log("ğŸ“¥ æ”¶åˆ°éŸ³è¨Š Blob:", blob);

          const audioUrl = URL.createObjectURL(blob);
          const audio = new Audio(audioUrl);
          audio.autoplay = true;
          audio.volume = 1.0;

          audio.play().then(() => {
            console.log("ğŸ”Š æ’­æ”¾æˆåŠŸï¼");
            document.getElementById("status").innerText = "ğŸ”Š æ’­æ”¾ AI å›è¦†ä¸­...";
            }).catch(err => {
            console.warn("âš ï¸ è‡ªå‹•æ’­æ”¾è¢«ç€è¦½å™¨é˜»æ“‹:", err);
            const btn = document.createElement("button");
            btn.innerText = "â–¶ï¸ æ’­æ”¾ AI å›è¦†";
            btn.onclick = () => audio.play();
            const status = document.getElementById("status");
            status.innerHTML = "";
            status.appendChild(btn);
});

// âœ… æ’­æ”¾å®Œç•¢å¾Œè‡ªå‹•æ¢å¾©å–šé†’ç›£è½
audio.onended = () => {
  console.log("ğŸ¤ AI å›è¦†æ’­æ”¾çµæŸï¼Œè‡ªå‹•å›åˆ°å–šé†’æ¨¡å¼");
  startWakeListener();
};

        // éŒ„éŸ³çµæŸå¾Œ â†’ è‡ªå‹•å›åˆ°å–šé†’æ¨¡å¼
        startWakeListener();
      };

      // ğŸ”¹ å•Ÿå‹•éŒ„éŸ³
      mediaRecorder.start();
      document.getElementById("status").innerText = "ğŸ™ï¸ éŒ„éŸ³ä¸­...(éœéŸ³ 3 ç§’æœƒè‡ªå‹•çµæŸ)";

      // ğŸ• å»¶é² 1 ç§’å¾Œå†å•Ÿå‹•éœéŸ³åµæ¸¬ï¼Œé¿å…èª¤åˆ¤é–‹é ­ç©ºç™½
      setTimeout(() => {
        console.log("ğŸ”Š å•Ÿå‹•éœéŸ³åµæ¸¬ï¼ˆå»¶é² 1 ç§’ï¼‰");
        detectSilence(stream);
      }, 1000);
    }

    // -----------------------------------------------------
    // [4] éœéŸ³åµæ¸¬ï¼šå¿…é ˆå…ˆæœ‰è²éŸ³æ‰é–‹å§‹å€’æ•¸
    // -----------------------------------------------------
    function detectSilence(stream) {
      const audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      source.connect(analyser);
      const buffer = new Uint8Array(analyser.fftSize);

      let silenceDuration = 0;  // å·²éœéŸ³ç§’æ•¸
      let hasVoice = false;     // æ˜¯å¦å·²å‡ºç¾äººè²
      let lastActive = 0;       // æœ€è¿‘æœ‰è²éŸ³æ™‚é–“æˆ³

      function loop() {
        analyser.getByteTimeDomainData(buffer);
        let max = Math.max(...buffer.map(v => Math.abs(v - 128)));
        const now = audioContext.currentTime;

        // ğŸ™ï¸ è‹¥éŸ³é‡è¶…éé–¾å€¼ï¼ˆåµæ¸¬åˆ°äººè²ï¼‰
        if (max > 15) { // å¯èª¿æ•´é–¾å€¼ 10ï½20 è¦–éº¥å…‹é¢¨éˆæ•åº¦
          if (!hasVoice) console.log("ğŸ—£ï¸ åµæ¸¬åˆ°äººè²ï¼Œé–‹å§‹å•Ÿå‹•éœéŸ³è¨ˆæ™‚ç›£æ§");
          hasVoice = true;
          lastActive = now;
          silenceDuration = 0;
        } else if (hasVoice) {
          // âœ… åªæœ‰åœ¨å‡ºç¾éäººè²å¾Œï¼Œæ‰é–‹å§‹ç´¯è¨ˆéœéŸ³æ™‚é–“
          silenceDuration = now - lastActive;
        }

        // ğŸ§  è‹¥å·²å‡ºç¾éäººè²ã€ä¸”éœéŸ³è¶…é 3 ç§’ â†’ è‡ªå‹•åœæ­¢éŒ„éŸ³
        if (hasVoice && silenceDuration >= 3 && mediaRecorder && mediaRecorder.state === "recording") {
          console.log("ğŸ›‘ åµæ¸¬åˆ° 3 ç§’ç„¡è²ï¼Œè‡ªå‹•çµæŸéŒ„éŸ³");
          mediaRecorder.stop();
          stream.getTracks().forEach(t => t.stop());
          return;
        }

        requestAnimationFrame(loop);
      }

      requestAnimationFrame(loop);
    }
  </script>
</body>
</html>



