<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8" />
  <title>ğŸ§ æ°¸é ç›£è½èªéŸ³æƒ…ç·’åˆ†æï¼ˆç©©å®šå¼·åŒ–ç‰ˆï¼‰</title>
  <style>
    body { font-family: "Microsoft JhengHei", sans-serif; text-align: center; margin: 28px auto; background: #fafafa; }
    input, button { padding: 8px; margin: 5px; width: 280px; font-size: 16px; }
    #status { margin-top: 8px; font-size: 16px; color: #333; min-height: 24px; }
    #emotionLight {
      width: 90px; height: 90px; border-radius: 50%; margin: 14px auto 8px;
      background: gray; box-shadow: 0 0 18px rgba(0,0,0,0.25); transition: background .25s, box-shadow .25s;
    }
    #logContainer {
      width: 90%; max-width: 760px; margin: 16px auto; text-align: left;
      background: #fff; border-radius: 12px; box-shadow: 0 0 10px rgba(0,0,0,.08);
      padding: 12px 14px; font-size: 15px; max-height: 70vh; overflow-y: auto;
    }
    .logItem { border-bottom: 1px solid #eee; padding: 10px 2px; }
    .logItem:last-child { border-bottom: none; }
    .emotionLine b { margin-right: 6px; }
    .userText { color: #000; font-style: italic; margin: 4px 0 6px; display: block; }
    .adviceText { color: #c0392b; margin-top: 3px; display: block; }
    .btnRow { margin-top: 6px; }
  </style>
</head>
<body>
  <h2>ğŸ¤– æ°¸é ç›£è½èªéŸ³æƒ…ç·’åˆ†æ</h2>
  <input id="webhookUrl" placeholder="n8n Webhook URL" /><br>
  <div class="btnRow">
    <button id="startBtn">ğŸš€ é–‹å§‹ç›£è½</button>
    <button id="stopBtn">ğŸ›‘ åœæ­¢ç›£è½</button>
  </div>

  <div id="emotionLight"></div>
  <div id="status">å°šæœªå•Ÿå‹•</div>

  <div id="logContainer"></div>

  <script>
    // ===== ç‹€æ…‹è®Šæ•¸ =====
    let n8nUrl = "";
    let audioCtx, analyser, micStream;
    let mediaRecorder;
    let audioChunks = [];
    let running = false;           // æ˜¯å¦è™•æ–¼ç›£è½æ¨¡å¼
    let isUploading = false;       // ä¸Šå‚³é–ï¼šé¿å…åŒæ™‚ä¸Šå‚³
    let isRecording = false;       // æ˜¯å¦æ­£åœ¨éŒ„éŸ³
    let cooldownUntil = 0;         // å†·å»çµæŸæ™‚é–“ï¼ˆé¿å…å‰›åœå°±åˆè§¸ç™¼ï¼‰
    let silenceStopper = null;     // åœæ­¢åµæ¸¬çš„å‡½æ•¸
    let recordStartTime = 0;       // éŒ„éŸ³é–‹å§‹æ™‚é–“ï¼ˆæœ€çŸ­æ™‚é•·åˆ¤æ–·ï¼‰
    const logs = [];               // æœ€è¿‘äº”ç­†

    // ===== UI å…ƒç´  =====
    const $status = document.getElementById("status");
    const $log = document.getElementById("logContainer");

    // ===== æƒ…ç·’é¡è‰²å°ç…§ =====
    const EMO_COLORS = {
      "é«˜èˆˆ": "#FFC107",   // é»ƒé‡‘
      "æ‚²å‚·": "#1E90FF",   // è—
      "ç”Ÿæ°£": "#FF3B30",   // ç´…
      "ä¸è€ç…©": "#8E44AD", // ç´«
      "è«·åˆº": "#FF8C00",   // æ©˜
      "å¹³éœ": "#2ECC71",   // ç¶ 
      "ä¸­ç«‹": "#27AE60"    // æ·±ç¶ 
    };

    // ===== äº‹ä»¶ç¶å®š =====
    window.addEventListener("DOMContentLoaded", () => {
      document.getElementById("startBtn").addEventListener("click", startListening);
      document.getElementById("stopBtn").addEventListener("click", stopListening);
    });

    // ===== ä¸»è¦æµç¨‹ =====
    async function startListening() {
      if (running) return;
      n8nUrl = document.getElementById("webhookUrl").value.trim();
      if (!n8nUrl) return alert("è«‹è¼¸å…¥ n8n Webhook URLï¼");
      try {
        await initMic();
        running = true;
        $status.textContent = "ğŸ§ éº¥å…‹é¢¨ç›£è½ä¸­...";
        startSilenceDetect(); // é–‹å§‹åµæ¸¬è²éŸ³
      } catch (e) {
        $status.textContent = "âŒ ç„¡æ³•å•Ÿç”¨éº¥å…‹é¢¨ï¼š" + e?.message;
      }
    }

    async function stopListening() {
      // é€²å…¥å†·å»æœŸï¼šé¿å…é—œé–‰çš„ç¬é–“åˆæŠ“åˆ°æ®˜ç•™éŸ³è¨Š
      cooldownUntil = performance.now() + 1200; // 1.2 ç§’å†·å»
      running = false;

      // åœæ­¢åµæ¸¬ loop
      if (silenceStopper) silenceStopper();
      silenceStopper = null;

      // è‹¥æ­£åœ¨éŒ„éŸ³ï¼Œå…ˆçµæŸéŒ„éŸ³ï¼ˆçµæŸå¾Œä¸è‡ªå‹•é‡é–‹åµæ¸¬ï¼‰
      if (mediaRecorder && mediaRecorder.state === "recording") {
        try { mediaRecorder.stop(); } catch {}
      }

      // é—œé–‰éŸ³è¨Šä¸²æµ & AudioContext
      if (micStream) { micStream.getTracks().forEach(t => t.stop()); micStream = null; }
      if (audioCtx && audioCtx.state !== "closed") { try { await audioCtx.close(); } catch {} audioCtx = null; }

      isRecording = false;
      $status.textContent = "ğŸ›‘ å·²åœæ­¢ç›£è½";
      showEmotion("ä¸­ç«‹");
    }

    async function initMic() {
      micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioCtx.createMediaStreamSource(micStream);
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      source.connect(analyser);
    }

    function startSilenceDetect() {
      const buffer = new Uint8Array(analyser.fftSize);
      let lastVoiceTime = 0;
      let rafId = 0;
      let stopped = false;

      const VOICE_THRESHOLD = 32;   // << æé«˜é–€æª»ï¼Œé™ä½å‘¼å¸è²èª¤è§¸
      const SILENCE_SEC = 1.8;      // << ç„¡è²æŒçºŒå¤šä¹…è¦–ç‚ºä¸€å¥çµæŸ
      const MIN_MS = 800;           // << æœ€çŸ­æœ‰æ•ˆèªéŸ³ 0.8s
      const MIN_SIZE = 6000;        // << æª”æ¡ˆå°æ–¼ 6KB è¦–ç‚ºé›œéŸ³

      // éŒ„éŸ³æ§åˆ¶
      function startRecording() {
        if (isRecording || isUploading) return;
        audioChunks = [];
        mediaRecorder = new MediaRecorder(micStream);
        mediaRecorder.ondataavailable = (e) => { if (e.data.size > 0) audioChunks.push(e.data); };
        mediaRecorder.onstop = () => uploadIfValid(MIN_MS, MIN_SIZE);
        recordStartTime = performance.now();
        mediaRecorder.start();
        isRecording = true;
        $status.textContent = "ğŸ™ï¸ éŒ„éŸ³ä¸­...";
      }

      async function stopRecording() {
        if (!isRecording) return;
        try {
          mediaRecorder.stop();
          $status.textContent = "ğŸ“¤ å‚³é€éŒ„éŸ³ä¸­...";
        } catch {}
        isRecording = false;
      }

      async function uploadIfValid(minDurationMs, minSize) {
        // è‹¥å·²åœæ­¢æ•´é«”ç›£è½ä¸”é‚„åœ¨å†·å»ï¼Œå°±ç›´æ¥ä¸Ÿæ£„
        if (!running && performance.now() < cooldownUntil) return;

        const duration = performance.now() - recordStartTime;
        const blob = new Blob(audioChunks, { type: "audio/webm" });
        if (duration < minDurationMs || blob.size < minSize) {
          console.log("ğŸ”‡ ç•¥éçŸ­é›œéŸ³ï¼š", { duration, size: blob.size });
          if (running && !stopped) loop(); // å›åˆ°åµæ¸¬
          return;
        }
        await sendToN8n(blob);
        if (running && !stopped) loop(); // å®Œæˆå¾Œå›åˆ°åµæ¸¬
      }

      function loop() {
        if (stopped || !running) return;
        analyser.getByteTimeDomainData(buffer);
        const now = audioCtx.currentTime;
        // å–æœ€å¤§åç§»é‡ï¼ˆ0-255 -> ä¸­å¿ƒ 128ï¼‰
        let max = 0;
        for (let i = 0; i < buffer.length; i++) {
          const amp = Math.abs(buffer[i] - 128);
          if (amp > max) max = amp;
        }

        if (max > VOICE_THRESHOLD && performance.now() > cooldownUntil) {
          // åµæ¸¬åˆ°äººè²
          lastVoiceTime = now;
          if (!isRecording && !isUploading) startRecording();
        } else if (isRecording) {
          const silentFor = now - lastVoiceTime;
          if (silentFor >= SILENCE_SEC) {
            stopRecording();
          }
        }

        rafId = requestAnimationFrame(loop);
      }

      loop();

      // å›å‚³åœæ­¢å‡½å¼
      silenceStopper = () => {
        stopped = true;
        if (rafId) cancelAnimationFrame(rafId);
      };
    }

    async function sendToN8n(blob) {
      if (isUploading) return;
      isUploading = true;

      try {
        const formData = new FormData();
        formData.append("audio_file", blob, "voice.webm");

        const res = await fetch(n8nUrl, { method: "POST", body: formData });
        const raw = await res.text();

        // è§£æç‚º JSONï¼ˆé˜²æ­¢å›å‚³å«æ›è¡Œ/å­—ä¸²åŒ– JSONï¼‰
        let result = null;
        try { result = JSON.parse(raw); } catch { console.warn("âš ï¸ é JSON å›å‚³ï¼š", raw); }

        if (result) {
          // æ›´æ–°ç‡ˆè™Ÿ + ç´€éŒ„
          showEmotion(result.emotion);
          addLog({
            text: result.text || "ï¼ˆæœªå–å¾—æ–‡å­—ï¼‰",
            emotion: result.emotion || "æœªçŸ¥",
            tone: result.tone || "",
            advice: result.advice || ""
          });
          $status.textContent = `ğŸ§  ${result.emotion || "æœªçŸ¥"} ï½œ ${result.tone || ""}`;
        } else {
          $status.textContent = "âš ï¸ æœªæ”¶åˆ°æœ‰æ•ˆçµæœ";
        }
      } catch (e) {
        console.error("âŒ ä¸Šå‚³/åˆ†æå¤±æ•—ï¼š", e);
        $status.textContent = "âŒ ä¸Šå‚³å¤±æ•—";
      } finally {
        isUploading = false;
      }
    }

    // ===== UIï¼šç‡ˆè™Ÿ + ç´€éŒ„ =====
    function showEmotion(emotion) {
      const light = document.getElementById("emotionLight");
      const color = EMO_COLORS[emotion] || "gray";
      light.style.background = color;
      light.style.boxShadow = `0 0 25px ${color}`;
    }

    function addLog(entry) {
      // åªä¿ç•™ 5 ç­†
      logs.unshift({ time: new Date().toLocaleTimeString(), ...entry });
      if (logs.length > 10) logs.pop();

      // ç‡ˆæ³¡å½©è‰²åœ–ç¤ºï¼ˆç”¨å­—è‰²ä¸Šè‰²ï¼‰
      const bulb = (emo) => {
        const c = EMO_COLORS[emo] || "#999";
        return `<span style="color:${c}">ğŸ’¡</span>`;
      };

      $log.innerHTML = logs.map(l => `
        <div class="logItem">
          <div>ğŸ•’ ${l.time}</div>
          <span class="userText">ğŸ—£ï¸ ä½ èªªï¼šã€Œ${escapeHtml(l.text)}ã€</span>
          <div class="emotionLine">ğŸ’­ æƒ…ç·’ï¼š<b>${l.emotion}</b>ã€€<span>${l.tone}</span></div>
          <span class="adviceText">ğŸ’¡ ${escapeHtml(l.advice)}</span>
        </div>
      `).join("");
    }

    // ç°¡å–®é¿å… XSS
    function escapeHtml(str) {
      return String(str || "")
        .replace(/&/g,"&amp;").replace(/</g,"&lt;")
        .replace(/>/g,"&gt;").replace(/"/g,"&quot;").replace(/'/g,"&#039;");
    }
  </script>
</body>
</html>
