import sounddevice as sd
import numpy as np
import webrtcvad
import queue
import time
from faster_whisper import WhisperModel
import requests
import os
from playsound import playsound
from scipy.io.wavfile import write

# === åŸºæœ¬è¨­å®š ===
WAKE_WORD = "å°æ™º"
N8N_WEBHOOK_URL = "https://ä½ çš„-n8nç¶²å€/webhook-test"  # æ”¹æˆä½ çš„ n8n Webhook
SAMPLE_RATE = 16000
CHANNELS = 1
REPLY_FILE = "reply.mp3"
MODEL_SIZE = "small"

# === åˆå§‹åŒ– faster-whisper ===
print("ğŸ§  è¼‰å…¥ faster-whisper æ¨¡å‹ä¸­...")
model = WhisperModel(MODEL_SIZE, device="auto")

# === åˆå§‹åŒ–èªéŸ³æ´»å‹•æª¢æ¸¬ (VAD) ===
vad = webrtcvad.Vad(2)
FRAME_DURATION = 30  # ms
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION / 1000)

# === éŒ„éŸ³ç›´åˆ°éœéŸ³ ===
def record_until_silence(silence_timeout=1.5):
    q_frames = queue.Queue()
    audio_buffer = []
    last_voice_time = time.time()

    def callback(indata, frames, time_info, status):
        q_frames.put(bytes(indata))

    with sd.RawInputStream(samplerate=SAMPLE_RATE,
                           blocksize=FRAME_SIZE,
                           dtype="int16",
                           channels=CHANNELS,
                           callback=callback):
        while True:
            frame = q_frames.get()
            is_speech = vad.is_speech(frame, SAMPLE_RATE)
            if is_speech:
                last_voice_time = time.time()
                audio_buffer.append(np.frombuffer(frame, dtype=np.int16))
            elif time.time() - last_voice_time > silence_timeout and audio_buffer:
                break

    if not audio_buffer:
        return None

    audio_data = np.concatenate(audio_buffer)
    return audio_data


# === èªéŸ³è¾¨è­˜ ===
def transcribe_audio(audio_data, lang=None):
    audio_float = audio_data.astype(np.float32) / 32768.0
    segments, _ = model.transcribe(audio_float, language=lang, beam_size=5)
    text = "".join([seg.text for seg in segments]).strip()
    return text


# === å‚³é€åˆ° n8n ===
def send_to_n8n(audio_data):
    try:
        print("ğŸ“¡ å‚³é€éŸ³è¨Šåˆ° n8n...")
        write("input.wav", SAMPLE_RATE, audio_data)
        with open("input.wav", "rb") as f:
            files = {"file": f}
            response = requests.post(N8N_WEBHOOK_URL, files=files, timeout=120)

        if response.status_code == 200:
            with open(REPLY_FILE, "wb") as f:
                f.write(response.content)
            print("ğŸ“© å·²æ”¶åˆ°å›è¦†éŸ³è¨Šã€‚")
            return REPLY_FILE
        else:
            print("âš ï¸ n8n å›å‚³éŒ¯èª¤:", response.status_code, response.text)
            return None
    except Exception as e:
        print("âŒ å‚³é€å¤±æ•—:", e)
        return None


# === æ’­æ”¾èªéŸ³ ===
def play_audio(file):
    if not os.path.exists(file):
        print("âš ï¸ æ‰¾ä¸åˆ°å›è¦†éŸ³è¨Šæª”æ¡ˆ")
        return
    print("ğŸ”Š æ’­æ”¾å›è¦†ä¸­...")
    playsound(file)


# === ä¸»è¿´åœˆ ===
if __name__ == "__main__":
    print("ğŸ¤– æ™ºæ…§æ©Ÿå™¨äººï¼ˆRealtime Faster-Whisper + å–šé†’è©ç‰ˆï¼‰å•Ÿå‹•å®Œæˆï¼")
    print(f"ğŸ’¤ èªªå‡ºã€Œ{WAKE_WORD}ã€å³å¯å–šé†’æˆ‘ã€‚")

    while True:
        # --- å–šé†’ç›£è½éšæ®µ ---
        audio_data = record_until_silence(silence_timeout=1.5)
        if audio_data is None:
            continue

        text = transcribe_audio(audio_data, lang="zh")  # å›ºå®šä¸­æ–‡ï¼Œé˜²èª¤åˆ¤
        if WAKE_WORD in text:
            print(f"âœ… åµæ¸¬åˆ°å–šé†’è©ã€Œ{WAKE_WORD}ã€ï¼é€²å…¥äº’å‹•æ¨¡å¼...")
            play_audio("beep.mp3") if os.path.exists("beep.mp3") else None

            # --- å°è©±éšæ®µ ---
            print("ğŸ¤ è«‹é–‹å§‹èªªè©±...")
            user_audio = record_until_silence(silence_timeout=1.5)
            if user_audio is not None:
                user_text = transcribe_audio(user_audio)
                print(f"ğŸ—£ï¸ ä½¿ç”¨è€…èªªï¼š{user_text}")
                reply = send_to_n8n(user_audio)
                if reply:
                    play_audio(reply)

            print("ğŸ” è¿”å›å¾…å‘½ç‹€æ…‹ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡å–šé†’...\n")
        else:
            print(f"ğŸ” ({text}) æœªåµæ¸¬åˆ°å–šé†’è©ï¼Œç¹¼çºŒç›£è½...")
