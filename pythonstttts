import os, time, queue, tempfile, warnings
import numpy as np
import sounddevice as sd
import webrtcvad
from scipy.io.wavfile import write
from faster_whisper import WhisperModel
import requests
from pydub import AudioSegment
from pydub.playback import play

# ===== åŸºæœ¬è¨­å®š =====
WAKE_WORD = "å°æ–‡"
N8N_WEBHOOK_URL = "http://localhost:5678/webhook/e0fba784-ca1b-4bdf-b7eb-0465aa973959"  # âš ï¸ æ”¹æˆä½ çš„ Production webhook
MODEL_SIZE = "small"
SAMPLE_RATE = 16000
CHANNELS = 1
VAD_AGGRESSIVENESS = 2
SILENCE_TIMEOUT_WAKE = 1.0
SILENCE_TIMEOUT_MAIN = 1.5

warnings.filterwarnings("ignore", category=UserWarning)
sd.default.samplerate = SAMPLE_RATE
sd.default.channels = CHANNELS

# æš«å­˜ç›®éŒ„
TEMP_DIR = os.path.join(tempfile.gettempdir(), "ai_bot")
os.makedirs(TEMP_DIR, exist_ok=True)
WAKE_WAV = os.path.join(TEMP_DIR, "wake.wav")
INPUT_WAV = os.path.join(TEMP_DIR, "input.wav")
REPLY_MP3 = os.path.join(TEMP_DIR, "reply.mp3")

print("ğŸ§  è¼‰å…¥ faster-whisper æ¨¡å‹ä¸­ï¼ˆCPU / int8ï¼‰...")
model = WhisperModel(MODEL_SIZE, device="cpu", compute_type="int8")
print("ğŸ–¥ï¸ å·²å•Ÿç”¨ CPU æ¨¡å¼ï¼ˆint8ï¼‰")

vad = webrtcvad.Vad(VAD_AGGRESSIVENESS)
FRAME_DURATION_MS = 30
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION_MS / 1000)

# ===== éŒ„éŸ³ + åµæ¸¬ =====
def record_until_silence(silence_timeout: float):
    q_frames = queue.Queue()
    audio_chunks = []
    last_voice = time.time()

    def cb(indata, frames, time_info, status):
        q_frames.put(bytes(indata))

    print(f"ğŸ™ï¸ éŒ„éŸ³ä¸­ï¼ˆéœéŸ³>{silence_timeout:.1f}s è‡ªå‹•çµæŸï¼‰...")
    with sd.RawInputStream(samplerate=SAMPLE_RATE, blocksize=FRAME_SIZE,
                           dtype="int16", channels=CHANNELS, callback=cb):
        while True:
            frame = q_frames.get()
            is_speech = vad.is_speech(frame, SAMPLE_RATE)
            if is_speech:
                last_voice = time.time()
                audio_chunks.append(np.frombuffer(frame, dtype=np.int16))
            elif audio_chunks and (time.time() - last_voice) > silence_timeout:
                break

    if not audio_chunks:
        print("ğŸ”‡ æœªåµæ¸¬åˆ°æœ‰æ•ˆäººè²")
        return None
    audio = np.concatenate(audio_chunks)
    return audio

def transcribe_np_int16(audio_np, lang=None):
    audio_f32 = audio_np.astype(np.float32) / 32768.0
    segments, _ = model.transcribe(audio_f32, language=lang, beam_size=5)
    text = "".join(seg.text for seg in segments).strip()
    return text

def save_wav(path, audio_np):
    write(path, SAMPLE_RATE, audio_np)

# ===== å‚³é€åˆ° n8n =====
def send_to_n8n(wav_path):
    try:
        print("ğŸ“¡ å‚³é€éŸ³è¨Šåˆ° n8n...")
        with open(wav_path, "rb") as f:
            # âœ… åŠ ä¸Šæª”åèˆ‡ MIME typeï¼Œæ¨¡æ“¬ç€è¦½å™¨è¡Œç‚º
            files = {
                "audio_file": ("voice.wav", f, "audio/wav")
            }
            resp = requests.post(N8N_WEBHOOK_URL, files=files, timeout=180)
        if resp.status_code == 200:
            with open(REPLY_MP3, "wb") as out:
                out.write(resp.content)
            print("ğŸ“© æ”¶åˆ°å›è¦†éŸ³è¨Š")
            return REPLY_MP3
        else:
            print(f"âš ï¸ n8n å›å‚³éŒ¯èª¤: {resp.status_code} {resp.text}")
            return None
    except Exception as e:
        print("âŒ ä¸Šå‚³å¤±æ•—ï¼š", e)
        return None

# ===== æ’­æ”¾éŸ³è¨Š =====
def play_audio(path):
    if not path or not os.path.exists(path):
        print("âš ï¸ æ‰¾ä¸åˆ°å›è¦†éŸ³è¨Š")
        return
    try:
        print("ğŸ”Š æ’­æ”¾å›è¦†ä¸­...")
        audio = AudioSegment.from_file(path)
        play(audio)
    except Exception as e:
        print("âŒ æ’­æ”¾å¤±æ•—ï¼š", e)

# ===== ä¸»æµç¨‹ =====
if __name__ == "__main__":
    print(f"ğŸ¤– æ™ºæ…§æ©Ÿå™¨äººï¼ˆå–šé†’è©ç‰ˆï¼‰å•Ÿå‹•å®Œæˆï¼èªªå‡ºã€Œ{WAKE_WORD}ã€å–šé†’æˆ‘ã€‚")
    while True:
        wake_audio = record_until_silence(SILENCE_TIMEOUT_WAKE)
        if wake_audio is None:
            continue
        save_wav(WAKE_WAV, wake_audio)
        wake_text = transcribe_np_int16(wake_audio, lang="zh")
        print("ğŸ—£ï¸ å–šé†’è¾¨è­˜ï¼š", wake_text)
        if WAKE_WORD not in wake_text:
            print("ğŸ’¤ æœªåµæ¸¬åˆ°å–šé†’è©ï¼ŒæŒçºŒç›£è½â€¦\n")
            continue

        print("âœ… å–šé†’æˆåŠŸï¼è«‹é–‹å§‹èªªè©±â€¦")
        main_audio = record_until_silence(SILENCE_TIMEOUT_MAIN)
        if main_audio is None:
            print("âš ï¸ æ²’æ”¶åˆ°ä¸»è¬›å…§å®¹ï¼Œå›åˆ°å¾…å‘½\n")
            continue
        save_wav(INPUT_WAV, main_audio)

        try:
            preview = transcribe_np_int16(main_audio, lang=None)
            print("ğŸ“ ä¸»è¬›è½‰æ–‡å­—ï¼ˆé è¦½ï¼‰ï¼š", preview)
        except Exception as e:
            print("ï¼ˆé è¦½è½‰æ–‡å­—å¤±æ•—ï¼Œä¸å½±éŸ¿ä¸Šå‚³ï¼‰", e)

        reply_path = send_to_n8n(INPUT_WAV)
        play_audio(reply_path)
        print("ğŸ” è¿”å›å¾…å‘½ç‹€æ…‹â€¦\n")
