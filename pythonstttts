import os, time, queue, tempfile, warnings, mimetypes
import numpy as np
import sounddevice as sd
import webrtcvad
from scipy.io.wavfile import write
from faster_whisper import WhisperModel
import requests
from pydub import AudioSegment
from pydub.utils import which

# ===== åŸºæœ¬è¨­å®š =====
WAKE_WORD = "å°æ–‡"
# âš ï¸ æ”¹æˆä½ çš„ Production Webhookï¼ˆé -testï¼‰ï¼Œä¸¦ç¢ºä¿ workflow å·² Activate
N8N_WEBHOOK_URL = "https://jose-cigarettes-mutual-tion.trycloudflare.com/webhook/e0fba784-ca1b-4bdf-b7eb-0465aa973959"

MODEL_SIZE = "small"
SAMPLE_RATE = 16000
CHANNELS = 1
VAD_AGGRESSIVENESS = 2
SILENCE_TIMEOUT_WAKE = 1.0     # å–šé†’æ®µéœéŸ³çµæŸæ™‚é–“
SILENCE_TIMEOUT_MAIN = 1.5     # ä¸»è¬›æ®µéœéŸ³çµæŸæ™‚é–“

# ï¼ˆå¯é¸ï¼‰å›ºå®šè£ç½®ç´¢å¼•ï¼Œé¿å…èˆ‡å…¶ä»–è»Ÿé«”æ¶è£ç½®ï¼ˆç”¨ print(sd.query_devices()) æŸ¥ï¼‰
INPUT_DEVICE = None   # ä¾‹å¦‚ 1
OUTPUT_DEVICE = None  # ä¾‹å¦‚ 3

# ä½ çš„å–šé†’ç¢ºèªéŸ³æª”ï¼ˆæ”¯æ´ wav/mp3/ogg/webmï¼‰ï¼Œè«‹æ”¾åˆ°åŒè³‡æ–™å¤¾æˆ–è‡ªè¨‚è·¯å¾‘
PROJECT_DIR = os.path.dirname(os.path.abspath(__file__))
WAKE_CONFIRM_FILE = os.path.join(PROJECT_DIR, "answer.ok.mp3")  # â† æ›æˆä½ çš„æª”å

warnings.filterwarnings("ignore", category=UserWarning)
sd.default.samplerate = SAMPLE_RATE
sd.default.channels = CHANNELS

# æš«å­˜è³‡æ–™å¤¾
TEMP_DIR = os.path.join(tempfile.gettempdir(), "ai_bot")
os.makedirs(TEMP_DIR, exist_ok=True)
WAKE_WAV  = os.path.join(TEMP_DIR, "wake.wav")
INPUT_WAV = os.path.join(TEMP_DIR, "input.wav")

# æŒ‡å®š ffmpeg è·¯å¾‘ï¼ˆè‹¥æœªåŠ å…¥ PATH è«‹æ”¹æˆä½ çš„ ffmpeg.exeï¼‰
AudioSegment.converter = which("ffmpeg") or r"C:\ffmpeg\bin\ffmpeg.exe"

print("ğŸ§  è¼‰å…¥ faster-whisper æ¨¡å‹ä¸­ï¼ˆCPU / int8ï¼‰...")
model = WhisperModel(MODEL_SIZE, device="cpu", compute_type="int8")
print("ğŸ–¥ï¸ å·²å•Ÿç”¨ CPU æ¨¡å¼ï¼ˆint8ï¼‰")

vad = webrtcvad.Vad(VAD_AGGRESSIVENESS)
FRAME_DURATION_MS = 30
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION_MS / 1000)

# ============ å°å·¥å…· ============
def has_wake_word(text: str) -> bool:
    """å¯¬é¬†åŒ¹é…å–šé†’è©ï¼šç§»é™¤ç©ºç™½å¾Œå†æ¯”å°"""
    return bool(text) and (WAKE_WORD in text.replace(" ", ""))

# ---------- å–šé†’ç¢ºèªéŸ³ï¼šå•Ÿå‹•æ™‚é å…ˆè§£ç¢¼ï¼Œä¹‹å¾Œå¿«é€Ÿæ’­æ”¾ ----------
WAKE_WAVE_F32 = None  # æœƒåœ¨å•Ÿå‹•æ™‚è¼‰å…¥
def prepare_wake_confirm():
    """å°‡ WAKE_CONFIRM_FILE è§£ç¢¼æˆèˆ‡ç³»çµ±ç›¸å®¹çš„ float32 æ³¢å½¢ï¼Œå­˜åˆ°è¨˜æ†¶é«”ã€‚"""
    global WAKE_WAVE_F32
    try:
        if not os.path.exists(WAKE_CONFIRM_FILE):
            print("âš ï¸ æ‰¾ä¸åˆ°å–šé†’éŸ³æª”ï¼š", WAKE_CONFIRM_FILE)
            WAKE_WAVE_F32 = None
            return

        seg = AudioSegment.from_file(WAKE_CONFIRM_FILE)         # è‡ªå‹•åˆ¤æ–·æ ¼å¼
        seg = seg.set_channels(CHANNELS).set_frame_rate(SAMPLE_RATE)

        samples = np.array(seg.get_array_of_samples())
        if seg.channels == 2:
            samples = samples.reshape((-1, 2))
        denom = float(1 << (8 * seg.sample_width - 1))
        WAKE_WAVE_F32 = (samples.astype(np.float32) / denom)
        print("ğŸ”” å–šé†’éŸ³å·²è¼‰å…¥ï¼š", WAKE_CONFIRM_FILE)
    except Exception as e:
        print("âŒ è¼‰å…¥å–šé†’éŸ³å¤±æ•—ï¼š", e)
        WAKE_WAVE_F32 = None

def play_wake_confirm():
    """æ’­æ”¾é è¼‰çš„å–šé†’éŸ³ï¼›è‹¥æœªè¼‰å…¥å‰‡ç”¨çŸ­ beep å¾Œå‚™ã€‚"""
    try:
        sd.stop()
    except Exception:
        pass
    if WAKE_WAVE_F32 is not None:
        try:
            sd.play(WAKE_WAVE_F32, samplerate=SAMPLE_RATE, device=OUTPUT_DEVICE, blocking=True)
            sd.stop()
            time.sleep(0.1)
            return
        except Exception as e:
            print("ï¼ˆæ’­æ”¾é è¼‰å–šé†’éŸ³å¤±æ•—ï¼Œæ”¹ç”¨ beepï¼‰", e)
    # å¾Œå‚™ï¼šçŸ­ beep
    dur = 0.12
    t = np.linspace(0, dur, int(SAMPLE_RATE*dur), False)
    wave = (np.sin(2*np.pi*1000*t) * 0.25).astype(np.float32)
    sd.play(wave, samplerate=SAMPLE_RATE, blocking=True)
    sd.stop()
    time.sleep(0.05)

# ============ éŒ„éŸ³ / STT ============
def record_until_silence(silence_timeout: float):
    q_frames = queue.Queue()
    audio_chunks = []
    last_voice = time.time()

    def cb(indata, frames, time_info, status):
        q_frames.put(bytes(indata))

    print(f"ğŸ™ï¸ éŒ„éŸ³ä¸­ï¼ˆéœéŸ³>{silence_timeout:.1f}s è‡ªå‹•çµæŸï¼‰...")
    try:
        with sd.RawInputStream(samplerate=SAMPLE_RATE, blocksize=FRAME_SIZE,
                               dtype="int16", channels=CHANNELS, callback=cb,
                               device=INPUT_DEVICE):
            while True:
                frame = q_frames.get()
                is_speech = vad.is_speech(frame, SAMPLE_RATE)
                if is_speech:
                    last_voice = time.time()
                    audio_chunks.append(np.frombuffer(frame, dtype=np.int16))
                elif audio_chunks and (time.time() - last_voice) > silence_timeout:
                    break
    except Exception as e:
        print("âŒ éŒ„éŸ³éŒ¯èª¤ï¼š", e)
        sd.stop()
        return None

    # é›¢é–‹ with å¾Œè¼¸å…¥æµå·²é—œé–‰ï¼›ä¿éšªåœä¸€æ¬¡
    sd.stop()

    if not audio_chunks:
        print("ğŸ”‡ æœªåµæ¸¬åˆ°æœ‰æ•ˆäººè²")
        return None
    return np.concatenate(audio_chunks)

def transcribe_np_int16(audio_np, lang=None):
    audio_f32 = audio_np.astype(np.float32) / 32768.0
    segments, _ = model.transcribe(audio_f32, language=lang, beam_size=5)
    return "".join(seg.text for seg in segments).strip()

def save_wav(path, audio_np):
    write(path, SAMPLE_RATE, audio_np)

# ============ èˆ‡ n8n æºé€š ============
def send_to_n8n(wav_path):
    try:
        print("ğŸ“¡ å‚³é€éŸ³è¨Šåˆ° n8n...")
        with open(wav_path, "rb") as f:
            files = {"audio_file": ("voice.wav", f, "audio/wav")}
            resp = requests.post(N8N_WEBHOOK_URL, files=files, timeout=180)

        ctype = resp.headers.get("Content-Type", "")
        print("ğŸ” n8n å›å‚³ Content-Type:", ctype)

        # éŸ³è¨Šé¡å‹æ‰å­˜ç‚ºæ’­æ”¾æª”
        if resp.status_code == 200 and ctype.startswith("audio/"):
            ext = mimetypes.guess_extension(ctype.split(";")[0]) or ".bin"
            reply_path = os.path.join(TEMP_DIR, f"reply{ext}")
            with open(reply_path, "wb") as out:
                out.write(resp.content)
            print("ğŸ“© æ”¶åˆ°å›è¦†éŸ³è¨Š â†’", reply_path)
            return reply_path

        # è‹¥ééŸ³è¨Šå›å‚³ï¼Œå¯«å…¥éŒ¯èª¤æª”ä¾¿æ–¼é™¤éŒ¯
        err_path = os.path.join(TEMP_DIR, "reply_error.txt")
        with open(err_path, "wb") as out:
            out.write(resp.content)
        print(f"âš ï¸ ééŸ³è¨Šå›å‚³ï¼ˆ{resp.status_code}ï¼‰å·²å¯«å…¥ï¼š{err_path}")
        return None

    except Exception as e:
        print("âŒ ä¸Šå‚³å¤±æ•—ï¼š", e)
        return None

# ============ æ’­æ”¾ n8n å›è¦†ï¼ˆpydub è§£ç¢¼ â†’ sounddevice æ’­æ”¾ï¼‰ ============
def play_audio_any(path):
    if not path or not os.path.exists(path):
        print("âš ï¸ æ‰¾ä¸åˆ°å›è¦†éŸ³è¨Š")
        return
    try:
        print("ğŸ”Š æ’­æ”¾å›è¦†ä¸­ï¼ˆè‡ªå‹•è§£ç¢¼ï¼‰...")
        seg = AudioSegment.from_file(path)                 # è‡ªå‹•åˆ¤æ–·æ ¼å¼
        seg = seg.set_channels(CHANNELS).set_frame_rate(SAMPLE_RATE)

        # è½‰æˆ numpy float32 (-1.0 ~ 1.0)
        samples = np.array(seg.get_array_of_samples())
        if seg.channels == 2:
            samples = samples.reshape((-1, 2))
        denom = float(1 << (8 * seg.sample_width - 1))
        audio_f32 = (samples.astype(np.float32) / denom)

        sd.stop()
        sd.play(audio_f32, samplerate=SAMPLE_RATE, device=OUTPUT_DEVICE, blocking=True)
        sd.stop()
        time.sleep(0.2)  # çµ¦é©…å‹•æ”¶å°¾ï¼Œé¿å…é€£çºŒåˆ‡æ›æ™‚å´©æ½°
    except Exception as e:
        print("âŒ æ’­æ”¾å¤±æ•—ï¼š", e)
        sd.stop()

# ============ ä¸»æµç¨‹ ============
if __name__ == "__main__":
    # å•Ÿå‹•å…ˆè¼‰å…¥ä½ æä¾›çš„å–šé†’éŸ³æª”
    prepare_wake_confirm()

    print(f"ğŸ¤– æ™ºæ…§æ©Ÿå™¨äººï¼ˆå–šé†’éŸ³æª”ç‰ˆï¼‰å•Ÿå‹•å®Œæˆï¼èªªå‡ºã€Œ{WAKE_WORD}ã€å–šé†’æˆ‘ã€‚")
    while True:
        try:
            # 1) ç­‰å¾…å–šé†’
            wake_audio = record_until_silence(SILENCE_TIMEOUT_WAKE)
            if wake_audio is None:
                continue
            save_wav(WAKE_WAV, wake_audio)
            wake_text = transcribe_np_int16(wake_audio, lang="zh")  # å–šé†’æ®µå›ºå®šç”¨ä¸­æ–‡è¼ƒç©©
            print("ğŸ—£ï¸ å–šé†’è¾¨è­˜ï¼š", wake_text)

            if not has_wake_word(wake_text):
                print("ğŸ’¤ æœªåµæ¸¬åˆ°å–šé†’è©ï¼ŒæŒçºŒç›£è½â€¦\n")
                continue

            # 2) å–šé†’æˆåŠŸï¼šæ’­æ”¾ä½ è‡ªå‚™çš„å–šé†’éŸ³æª”
            play_wake_confirm()

            # 3) ä¸»è¬›éšæ®µ
            print("âœ… å–šé†’æˆåŠŸï¼è«‹é–‹å§‹èªªè©±â€¦")
            main_audio = record_until_silence(SILENCE_TIMEOUT_MAIN)
            if main_audio is None:
                print("âš ï¸ æ²’æ”¶åˆ°ä¸»è¬›å…§å®¹ï¼Œå›åˆ°å¾…å‘½\n")
                continue
            save_wav(INPUT_WAV, main_audio)

            # ï¼ˆå¯é¸ï¼‰é è¦½è½‰æ–‡å­—
            try:
                preview = transcribe_np_int16(main_audio, lang=None)
                print("ğŸ“ ä¸»è¬›è½‰æ–‡å­—ï¼ˆé è¦½ï¼‰ï¼š", preview)
            except Exception as e:
                print("ï¼ˆé è¦½è½‰æ–‡å­—å¤±æ•—ï¼Œä¸å½±éŸ¿ä¸Šå‚³ï¼‰", e)

            # 4) é€ n8nï¼Œæ’­æ”¾å›è¦†ï¼Œå›åˆ°å¾…å‘½
            reply_path = send_to_n8n(INPUT_WAV)
            play_audio_any(reply_path)
            print(f"ğŸ” å›åˆ°å¾…å‘½ç‹€æ…‹â€¦ï¼ˆèªªã€{WAKE_WORD}ã€å¯å†æ¬¡å–šé†’ï¼‰\n")

        except KeyboardInterrupt:
            print("\nğŸ›‘ å·²æ‰‹å‹•çµæŸç¨‹å¼ã€‚")
            break
        except Exception as e:
            print("âš ï¸ ç™¼ç”Ÿä¾‹å¤–ï¼š", e)
            time.sleep(1)
